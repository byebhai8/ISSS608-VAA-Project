[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Group 10",
    "section": "",
    "text": "Team Members\n\nBhairavi Vairavelu: LinkedIn | GitHub\nTao Meizhu (Victoria): LinkedIn | GitHub\nYin Hang: LinkedIn | GitHub"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Visual Analysis of Visitor Arrivals in Singapore",
    "section": "",
    "text": "This is a Quarto website that will be used for ISSS608 Visual Analytics and Applications Project.\nProject Summary\nIn this project, our team, Group 10, will be building a web-enabled visual analytics platform using R Shiny application. The aim of this project is to provide key insights using the data we have gathered and cleansed, allowing the user to draw meaningful conclusions from our visualizations."
  },
  {
    "objectID": "project_proposal.html",
    "href": "project_proposal.html",
    "title": "Project Proposal",
    "section": "",
    "text": "This page contains our project proposal.\n\n1. Overview\nIn this project, our team, Group 10, will be building a web-enabled visual analytics platform using R Shiny application. The aim of this project is to provide key insights using the data we have gathered and cleansed, allowing the user to draw meaningful conclusions from our visualizations.\n\n\n2. Project Topic\nThe tourism sector in Singapore has been impacted by the COVID-19 pandemic significantly, leading to a decline in tourist arrivals and a shift in travel patterns. “A sustainable tourism is something that is becoming increasingly important in the next 10 years”, said Mr. Christopher Khoo, the managing director for international tourism consultancy Master Consult Services. An important question to address is how to better understand the challenges the tourism industry face so that we can implement specific measures when planning and managing tourism in Singapore. Without such measures, Singapore’s tourism could face numerous negative impacts that may affect their sustainability and competitiveness on the global market, such as the impact by COVID-19, increased traffic congestion, and conflicts between visitors and hosts (hotels).\nOur aim is to visualize and analyse historical data and provide a predictive model with accuracy, which will help the tourism sector and stakeholders to draw insights easily, take actions quickly and gain advantages in terms of sustainability and competitiveness in a very competitive global tourism industry when the world just sprung back into a more vibrant sector.\n\n\n3. Motivation\nTourism industry plays a significant part in the economy of Singapore, contributing to employment, foreign exchange earnings as well as overall economic growth. However, the number of international tourist arrivals in Singapore dropped sharply with the onset of the COVID-19 pandemic. The number gradually bounced back in 2022. Despite the significant annual increase, international tourism arrivals in Singapore remained below pre-pandemic levels, totaling at approximately 63 million in 2022. It became critical on how to forecast the number of tourists based on the given historical time-series data and multiple factors.\nIn this project, we will visualize and analyse the International Visitor Arrivals by Inbound Tourism Markets dataset, and build an interactive R Shiny application for forecasting of the next 10 years. Singapore tourism sectors can draw insights and take actions based on the insights they gain from the R Shiny application and the Quarto website that we are developing.\n\n\n4. Related Work\nPrevious studies have built visualizations of the tourism sector in Singapore using various methods, including Tableau dashboard and static charts. However, there has been limited research on visual analysis of the sector, especially time series forecasting. This would be the main focus topic of our project.\nTime series forecasting is part of predictive analytics. It can show likely changes in the data, such as seasonality and cyclic behaviors, which provide a better understanding of data variables and helps forecast better. A model based on deep learning with time series imaging is proposed. The model consists of three parts: sequence image generation, image feature extraction, and model training.\n\n\n5. Dataset\nThe dataset that will be used for this project is from: https://www.singstat.gov.sg/\n\nOnce downloaded, this single Excel file contains the following sheets: Content, T1, T2 and T3. The sheet Content basically describes the information that is captured in the different sheets in the Excel file.\nThe following is a snapshot of the sheet T1, which contains information about the monthly international visitor arrivals grouped by the inbound tourism market.\n\nIn this sheet, we have the following information:\n\nThe data series column captures\n\nThe total international visitor arrivals\nThe regions and countries the visitors arrived from\n\nThe remaining columns represent the month and year of the data\n\nThe following is a snapshot of the sheet T2, which contains information about the monthly international visitor arrivals grouped by their gender and age group.\n\nIn this sheet, we have the following information:\n\nThe data series column captures\n\nThe total international visitor arrivals\nThe gender of the visitors\nThe age group of the visitors\n\nThe remaining columns represent the month and year of the data\n\nThe following is a snapshot of the sheet T3, which contains information about the monthly international visitor arrivals grouped by their length of stay.\n\nIn this sheet, we have the following information:\n\nThe data series column captures\n\nThe total international visitor arrivals\nThe length of stay of the visitors\nThe average length of stay of the visitors\n\nThe remaining columns represent the month and year of the data\n\n\n\n6. Possible Approach\nThe dataset will be cleansed, processed, and transformed into a suitable format for visual analysis. This analysis will be performed using various R packages. The analysis will mainly focus on the following aspects:\n\nKey insights into visitor arrivals in Singapore such as where they are from, their gender, age group and their length of stay in Singapore\nTrends in visitor arrivals in Singapore, before and after the COVID-19 pandemic.\nForecasting of visitor arrivals for the next 1 to 10 years\n\nThe results of the visual analysis will be presented in the form of interactive charts in a R Shiny application. The insights generated will be useful for stakeholders in the tourism and hotel industries, as well as policymakers and researchers, in understanding the trends and challenges facing the tourism sector in Singapore.\n\n\n7. Storyboard\nOur R Shiny application is titled “Visitor Arrival Analysis”. This application contains three sections – Home, Explore and Forecast.\n\nHome Page\nThe following is the storyboard for the Home Page, which also serves as a summary page.\n\nIn this home page, the following summary level information will be captured:\n\nText label to display the total visitor arrivals\nText label to display the country most of the visitors are from\nText label to display the age range most of the visitor fall into\nText label to display the average number of days visitors stayed\n\nThese text labels aim to provide quick insights into the visitor arrivals in Singapore. Moreover, these labels will be affected by the following filters:\n\nSlider to control the range of years of data, built using the sliderInput()\nMulti-select checkbox to control the quarters of data, built using the checkboxGroupInput()\nMulti-select dropdown box to control the months of data, built using the selectInput()\n\nThis home page will also contain a time series line chart to depict the number of visitors across time. This will be built using the tidyverse package (ggplot2) in R, utilizing the geom function of geom_line().\nThis chart will be controlled by the Metrics filter which controls the metric that is displayed in the line chart. The metrics in this filter are “By Region”, “By Country”, “By Gender”, “By Age Group” and “By Length of Stay”. This filter will be a single-select dropdown box that is built using the selectInput().\nA submit button, built using actionButton(), is included in this page to allow users to click and refresh the home page to reflect their filter selections.\nThe key thing to note for this page is that the metrics filter will only affect the time series line chart. Moreover, this metrics will represent the colour codes in the line chart. Therefore, we have included a section on the right to display the legends based on the metrics chosen by the user.\n\n\nExplore Page\nThe following is the storyboard for the Explore Page. This page will contain a total of 4 tabs – By Geography, By Gender, By Age Group and By Length of Stay.\nBy Geography\nThe storyboard below is an example of how the By Geography tab will be built.\n\nIn this explore page, the following filters will be provided to users:\n\nSlider to control the range of years of data, built using the sliderInput()\nMulti-select checkbox to control the quarters of data, built using the checkboxGroupInput()\nMulti-select dropdown box to control the months of data, built using the selectInput()\n\nThis page will also contain the following charts:\n\nTree map to depict the number of visitors by region, built using the treemap package in R\nBar chart to depict the number of visitors by country, built using the tidyverse package (ggplot2) in R, utilizing the geom function of geom_bar()\n\nIn this explore page, users can click on a cell in the tree map to filter the bars displayed in the bar chart. For example, if the user were to click on the cell representing the region of Europe, the bars will be filtered to only display countries which are in the region of Europe, such as France and Belgium.\nA mock up designed using Tableau is shown below:\n\nA submit button, built using actionButton(), will also be included in this page to allow users to click and refresh the explore page to reflect their filter selections.\nBy Gender\nThe storyboard below is another example of how the Explore Page will be built. This storyboard focuses on what elements the By Gender tab will contain.\n\nIn this explore page, the following filters will be provided to users:\n\nSlider to control the range of years of data, built using the sliderInput()\nMulti-select checkbox to control the quarters of data, built using the checkboxGroupInput()\nMulti-select dropdown box to control the months of data, built using the selectInput()\n\nThis page will also contain the following charts:\n\nPie chart to depict the number of visitors by gender across time, built using the tidyverse package (ggplot2) in R, utilizing the geom function of geom_bar() and coord_polar to make it circular to resemble a pie\n\nAn alternative to this would be to use the pie() function that is natively provided in R\n\nStacked Bar chart to depict the number of visitors by gender for the selected period, built using the tidyverse package (ggplot2) in R, utilizing the geom function of geom_col() to show the proportion of data (percentage of total)\n\nA mock up designed using Tableau is shown below:\n\nA submit button, built using actionButton(), will also be included in this page to allow users to click and refresh the explore page to reflect their filter selections.\n\n\nForecast Page\nThe following is the storyboard for the Forecast Page.\n\nThis page is similar to the summary page, whereby we have the filters for the various data periods, as well as the filters to control the metrics we want to view in the time series line chart. With this metrics filter, the user can forecast the number of visitors based on their chosen metric.\nIn this forecast page, however, we modify the year filter. In the summary page, the user will be able to change the range of years they want to view the data for. On the other hand, in the forecast page, they will be given the option to forecast for the next 1 to 10 year range using the sliderInput().\nWhen user clicks on the submit button, which is built using the actionButton(), users will be able to see an animation that depicts how the number of visitors are predicted to be for the next given number of years. This animation will be built using the gganimate package. Additionally, we will be utilizing the gifski package to convert the animated plot into a GIF format, and the transformr package to smoothly animate the lines in the time series plot.\nTo ease the interpretability of this page, we will also include a tabular view below the time series line chart to capture the number of visitors that are forecast for the next given number of years. This will be built using the DT package in R, which provides an interface to the DataTables library that is in JavaScript.\nTo summarize, the following R packages will be used in our project:\n\nggplot2\ntreemap\ngganimate\ngifski\ntransformr\nDT\n\n\n\n\n8. Possible Obstacles\nOne of the main obstacles that we are facing is that the dataset is 1 dimensional and cleansed. For instance, we will be unable to match a record of data to two categorical variables. One example is that we will be unable to determine how many visitors in the age group of 15 to 19 years old are male. Due to this limitation, our team is in the midst of requesting for the raw data files from Singapore Tourism Board.\nAs we are facing this obstacle, the team is also unable to determine the various analysis that could be done with the raw dataset. Due to not having the raw data and having aggregated data, we are unsure on the possibilities of building analytical visualizations such as scatterplots, boxplots and violin plots.\nDue to this limitation, we intend to rework the storyboard once gaining access to the raw dataset.\nHowever, keeping in mind that there is a possibility that we are not awarded with the raw dataset, the team has a secondary plan of utilizing additional datasets such as Tourism Receipts and Hotel Statistics to boost up the value of our visual analysis.\nAnother obstacle that the team might face is the data wrangling portion of this project. As described in the Dataset section, we have multiple categorical variables in a single column, such as Region and Country. Our team intends to wrangle and transform these variables into a clean and usable format before proceeding to create the various R visualizations. Due to an unfamiliarity with various R packages, the team sees this as an obstacle. However, with research of R documentations, practice of R code and exploration of the various packages, we are certain that we will overcome this.\n\n\n9. Timeline & Work Allocation\nThe following is our Gantt chart for the project timeline:\n\nThe following is the Work Allocation between the project members:\n\nMeizhu: Data Exploration and Forecast Model Building\nYin Hang: Netlify Presentation and Animation\nBhairavi: R Shiny App Building\n\nThis concludes the submission for Group 10’s Project Proposal. Thank you!"
  },
  {
    "objectID": "working_script.html",
    "href": "working_script.html",
    "title": "Working Script",
    "section": "",
    "text": "1. Load necessary libraries\n\npacman::p_load(readxl, tidyverse)\n\n\n\n2. Load the dataset\n\nvaByMarketRaw <- read_excel(\"outputFile -International Visitor Arrivals.xlsx\", sheet = \"T1\", skip = 10)\nvaByDemoRaw <- read_excel(\"outputFile -International Visitor Arrivals.xlsx\", sheet = \"T2\", skip = 10)\nvaByStayRaw <- read_excel(\"outputFile -International Visitor Arrivals.xlsx\", sheet = \"T3\", skip = 9)\n\n\n\n3. Cleansing the dataset\n\n3.1 Tourism Markets file\nThis file\n\ncontains the international visitor arrivals by inbound tourism markets (monthly)\nexcludes arrivals of Malaysians by land\nfeb 1991 has a sharp decline due to Gulf crisis\ndata for Germany prior to 1991 refers to West Germany only\nall numbers are counts\n\nThe following was done to cleanup the vaByMarketRaw dataframe:\n\nremove the bottom few rows as they were unnecessary for our visualizations\ncreate a new column to assign the value of Region to the respective Countries\nrename fields and rearrange the columns\nfilter out rows that are not needed anymore\npivot date (month-year) and the number of visitors to reduce the number of columns\n\n\nvaByMarket <- slice(vaByMarketRaw, 2:(62))\n\ncolnames(vaByMarket)[1] <- \"Data\"\n\nvaByMarket$Region <-\n  ifelse(vaByMarket$Data %in% c(\"Brunei Darussalam\", \"Indonesia\", \"Malaysia\", \"Myanmar\", \"Philippines\", \"Thailand\", \"Vietnam\", \"Other Markets In Southeast Asia\"), \"Southeast Asia\",\n  ifelse(vaByMarket$Data %in% c(\"China\", \"Hong Kong SAR\", \"Taiwan\", \"Other Markets In Greater China\"), \"Greater China\",\n  ifelse(vaByMarket$Data %in% c(\"Japan\", \"South Korea\", \"Other Markets In North Asia\"), \"North Asia\",\n  ifelse(vaByMarket$Data %in% c(\"Bangladesh\", \"India\", \"Pakistan\", \"Sri Lanka\", \"Other Markets In South Asia\"), \"South Asia\",\n  ifelse(vaByMarket$Data %in% c(\"Iran\", \"Israel\", \"Kuwait\", \"Saudi Arabia\", \"United Arab Emirates\", \"Other Markets In West Asia\"), \"West Asia\",\n  ifelse(vaByMarket$Data %in% c(\"Canada\", \"USA\", \"Other Markets In Americas\"), \"Americas\",\n  ifelse(vaByMarket$Data %in% c(\"Belgium & Luxembourg\", \"Denmark\", \"Finland\", \"France\", \"Germany\", \"Italy\", \"Netherlands\", \"Norway\", \"Rep Of Ireland\", \"Russian Federation\", \"Spain\", \"Sweden\", \"Switzerland\", \"United Kingdom\", \"Other Markets In Europe\"), \"Europe\",\n  ifelse(vaByMarket$Data %in% c(\"Australia\", \"New Zealand\", \"Other Markets In Oceania\"), \"Oceania\",\n  ifelse(vaByMarket$Data %in% c(\"Egypt\", \"Mauritius\", \"South Africa (Rep Of)\", \"Other Markets In Africa\"), \"Africa\",\n  ifelse(vaByMarket$Data %in% c(\"Others\"), \"Others\", \"NA\"\n  ))))))))))\n\nvaByMarket <- vaByMarket %>%\n  select(542, 1, 2:541)\n\ncolnames(vaByMarket)[2] <- \"Country\"\n\n# sapply(vaByMarket, class)\n\nvaByMarket <- vaByMarket %>%\n  mutate_at(vars(-one_of(\"Region\", \"Country\")), as.numeric) %>%\n  filter(vaByMarket$Region != \"NA\") %>%\n  pivot_longer(cols = ! c(\"Region\", \"Country\"), names_to = \"Period\", values_to = \"Visitors\") %>%\n  mutate(Period = as.Date(paste(Period, \"01\"), \"%Y %B %d\")) %>%\n  mutate(Year = year(Period))\n\n\n\n\n4. Preparations for visualizations\nto find the total number of visitors (regardless of date range):\n\ntotalVisitors <- sum(vaByMarket$Visitors, na.rm = TRUE)\ntotalVisitors\n\n[1] 325005202\n\n\nto find the min and max year:\n\nminYear <- min(year(vaByMarket$Period))\nminYear\n\n[1] 1978\n\nmaxYear <- max(year(vaByMarket$Period))\nmaxYear\n\n[1] 2022\n\n\nto find the country where most visitors are from:\n\nvisitorsByCountry <- vaByMarket %>%\n  group_by(Country) %>%\n  summarize(Visitors = sum(Visitors, na.rm = TRUE))\n  \nvisitorsByCountry <- visitorsByCountry[order(visitorsByCountry$Visitors, decreasing = TRUE), ]\nvisitorsByCountry\n\n# A tibble: 52 × 2\n   Country        Visitors\n   <chr>             <dbl>\n 1 Indonesia      50918113\n 2 China          34648115\n 3 Japan          29394650\n 4 Australia      24989059\n 5 Malaysia       21009122\n 6 India          20987273\n 7 United Kingdom 15116531\n 8 USA            14620454\n 9 South Korea    11942521\n10 Hong Kong SAR  11765677\n# … with 42 more rows\n\nmostFrom <- head(visitorsByCountry$Country, 1)\nmostFrom\n\n[1] \"Indonesia\"\n\n\nto find the number of countries that visited us:\n\ntemp <- vaByMarket[vaByMarket$Year >= 1984 & vaByMarket$Year <= 1990, ]\n\nnumCountries <- nrow(temp %>%\n    filter(!is.na(Visitors)) %>%\n    count(Country))\nnumCountries\n\n[1] 33\n\n\nto list of regions\n\nlistRegions <- unique(vaByMarket$Region)\nlistRegions\n\n [1] \"Southeast Asia\" \"Greater China\"  \"North Asia\"     \"South Asia\"    \n [5] \"West Asia\"      \"Americas\"       \"Europe\"         \"Oceania\"       \n [9] \"Africa\"         \"Others\"        \n\n\nxx\n\n\n5. Visualizations\nplotting visitors across time chart:\ninstall the timetk package (recommended by Prof Kam)\n\npacman::p_load(timetk, lubridate, ggplot2, plotly, ggHoriPlot)\n\nTime Series Plot for Overall Trend (timetk)\n\ntimeSeriesOverall <- vaByMarket %>%\n  group_by(Period) %>%\n  summarise(Visitors = sum(Visitors, na.rm = TRUE))\n\ntimeSeriesOverall %>%\n  plot_time_series(Period, Visitors, .interactive = TRUE)\n\n\n\n\n\nCycle Plot for Overall Trend TBC, Cycle Plot is not working!!\n\n# vaByMarket[is.na(vaByMarket)] = 0\n# \n# monthAvg <- vaByMarket %>%\n#   mutate(Month = month(Period)) %>%\n#   group_by(Month) %>%\n#   summarise(avgValue = mean(Visitors))\n# \n# cyclePlot <- vaByMarket %>%\n#   group_by(Period) %>%\n#   summarise(Visitors = sum(Visitors, na.rm = TRUE)) %>%\n#   mutate(Month = as.character(Period, format = '%b')) %>%\n#   mutate(Visitors = round(Visitors/1000, digits = 0))\n# \n# figCyclePlot <- ggplot() +\n#   geom_line(data = cyclePlot,\n#             aes(x = as.character(Period, format = '%y'),\n#                 y = Visitors,\n#                 group = Month)) +\n#   geom_hline(aes(yintercept = avgValue),\n#              data = monthAvg,\n#              colour = \"red\",\n#              size = 0.3) +\n#   labs(x = \"Date\", y = \"No. of Visitors\", title = \"Overall Trend of Visitor Arrivals by month and year, 1978 to 2022\") +\n#   facet_grid(~ factor(Month, levels = c(\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"))) +\n#   theme_bw()\n# \n# ggplotly(figCyclePlot)\n\nCompare two regions using the Horizon Plot for Regional Trend?\n\nvaByMarket %>%\n  group_by(Period, Region) %>%\n  summarise(Visitors = sum(Visitors)) %>%\n  filter(Region == \"South Asia\")  %>%\n  ggplot() +\n  geom_horizon(aes(x = Period, y =  Visitors), origin = \"midpoint\", horizonscale = 6) +\n  facet_grid(Region~.) +\n  scale_fill_hcl(palette = \"RdBu\") +\n  scale_x_date(expand = c(0,0), date_breaks = \"3 year\", date_labels = \" %b %y\") +\n  theme_minimal() +\n  theme(panel.spacing.y = unit(0, \"lines\"), \n        strip.text.y = element_text(size = 10, angle = 0, hjust = 0),\n        legend.position = 'none',\n        axis.text.y = element_blank(),\n        axis.text.x = element_text(size = 7),\n        axis.title.y = element_blank(),\n        axis.title.x = element_blank(),\n        axis.ticks.y = element_blank(),\n        panel.border = element_blank())\n\n\n\n\nTime Series Plot for Regional Trend (ggplotly)\n\ntimeseriesRegion <- vaByMarket %>%\n  group_by(Region, Period) %>%\n  summarise(Visitors = sum(Visitors, na.rm = TRUE)) %>%\n  mutate(Visitors = round(Visitors/1000, digits = 0))\n\nfigTimeseriesRegion <- ggplot(data = timeseriesRegion, aes(x = Period, y = Visitors)) +\n  geom_line(aes(colour = Region)) +\n  labs(x = \"Date\", y = \"No. of Visitors (K)\", title = \"Overall Trend of Visitor Arrivals by Region, 1978 to 2022\") +\n  theme_bw()\n\nggplotly(figTimeseriesRegion)\n\n\n\n\n\nTime Series Plot for Country Trend (ggplotly)\n\ntimeseriesCountry <- vaByMarket %>%\n  group_by(Country, Period) %>%\n  summarise(Visitors = sum(Visitors, na.rm = TRUE)) %>%\n  mutate(Visitors = round(Visitors/1000, digits = 0))\n\nfigTimeseriesCountry <- ggplot(data = timeseriesCountry, aes(x = Period, y = Visitors)) +\n  geom_line(aes(colour = Country)) +\n  labs(x = \"Date\", y = \"No. of Visitors (K)\", title = \"Overall Trend of Visitor Arrivals, 1978 to 2022\") +\n  theme_bw()\n\nggplotly(figTimeseriesCountry)\n\n\n\n\n\n\n\n5. Forecasting\nreference: https://www.r-bloggers.com/2020/06/introducing-modeltime-tidy-time-series-forecasting-using-tidymodels/\nloading libraries\n\npacman::p_load(modeltime, kernlab, reactable, tidymodels)\n\nonly keep the date and value columns for forecasting\n\nvaByMarketTable <- vaByMarket %>%\n  group_by(Period) %>%\n  summarise(visitors = round(sum(Visitors, na.rm = TRUE))/1000) %>% # converted to thousands\n  set_names(c(\"date\", \"value\"))\nvaByMarketTable\n\n# A tibble: 540 × 2\n   date       value\n   <date>     <dbl>\n 1 1978-01-01  99.0\n 2 1978-02-01  87.0\n 3 1978-03-01  95.5\n 4 1978-04-01  84.2\n 5 1978-05-01  89.7\n 6 1978-06-01  78.5\n 7 1978-07-01  96.4\n 8 1978-08-01 113. \n 9 1978-09-01  87.8\n10 1978-10-01  99.6\n# … with 530 more rows\n\n\nlet’s create a train/test set”\n\nsplits <- vaByMarketTable %>%\n  time_series_split(\n    assess = \"3 years\",\n    cumulative = TRUE\n  )\nsplits\n\n<Analysis/Assess/Total>\n<504/36/540>\n\n\nlet’s plot the train/test split to visualize the split:\n\nsplits %>%\n  tk_time_series_cv_plan() %>%\n  plot_time_series_cv_plan(date, value, .interactive = FALSE)\n\n\n\n\nwe will modelling using modeltime and parsnip libraries\nBasic Auto ARIMA fitting\n\nmodelFitArima <- arima_reg(\n  non_seasonal_ar = 2,\n  non_seasonal_differences = 1,\n  non_seasonal_ma = 2\n) %>%\n  set_engine(\"auto_arima\") %>%\n  fit(value ~ date, training(splits))\nmodelFitArima\n\nparsnip model object\n\nSeries: outcome \nARIMA(2,1,2)(0,1,2)[12] \n\nCoefficients:\n          ar1     ar2      ma1      ma2     sma1     sma2\n      -0.0794  0.7370  -0.0192  -0.9356  -0.5090  -0.1233\ns.e.   0.0442  0.0444   0.0240   0.0251   0.0453   0.0401\n\nsigma^2 = 1498:  log likelihood = -2492.86\nAIC=4999.71   AICc=4999.94   BIC=5029.09\n\n\nProphet\n\nmodelFitProphet <- prophet_reg() %>%\n  set_engine(\"prophet\", yearly.seasonality = TRUE) %>%\n  fit(value ~ date, training(splits))\nmodelFitProphet\n\nparsnip model object\n\nPROPHET Model\n- growth: 'linear'\n- n.changepoints: 25\n- changepoint.range: 0.8\n- yearly.seasonality: 'auto'\n- weekly.seasonality: 'auto'\n- daily.seasonality: 'auto'\n- seasonality.mode: 'additive'\n- changepoint.prior.scale: 0.05\n- seasonality.prior.scale: 10\n- holidays.prior.scale: 10\n- logistic_cap: NULL\n- logistic_floor: NULL\n- extra_regressors: 0\n\n\nMachine Learning Models - create a pre-processing recipe - create model specs - use workflow to combine model specs, pre-processing and fit model\nPre-processing Recipe:\n\nrecipeSpecs <- recipe(value ~ date, training(splits)) %>%\n  step_timeseries_signature(date) %>%\n  step_dummy(all_nominal())\n\nrecipeSpecs %>%\n  prep() %>%\n  juice()\n\n# A tibble: 504 × 44\n   date       value date_index…¹ date_…² date_…³ date_…⁴ date_…⁵ date_…⁶ date_…⁷\n   <date>     <dbl>        <dbl>   <int>   <int>   <int>   <int>   <int>   <int>\n 1 1978-01-01  99.0    252460800    1978    1977       1       1       1       0\n 2 1978-02-01  87.0    255139200    1978    1978       1       1       2       1\n 3 1978-03-01  95.5    257558400    1978    1978       1       1       3       2\n 4 1978-04-01  84.2    260236800    1978    1978       1       2       4       3\n 5 1978-05-01  89.7    262828800    1978    1978       1       2       5       4\n 6 1978-06-01  78.5    265507200    1978    1978       1       2       6       5\n 7 1978-07-01  96.4    268099200    1978    1978       2       3       7       6\n 8 1978-08-01 113.     270777600    1978    1978       2       3       8       7\n 9 1978-09-01  87.8    273456000    1978    1978       2       3       9       8\n10 1978-10-01  99.6    276048000    1978    1978       2       4      10       9\n# … with 494 more rows, 35 more variables: date_day <int>, date_hour <int>,\n#   date_minute <int>, date_second <int>, date_hour12 <int>, date_am.pm <int>,\n#   date_wday <int>, date_wday.xts <int>, date_mday <int>, date_qday <int>,\n#   date_yday <int>, date_mweek <int>, date_week <int>, date_week.iso <int>,\n#   date_week2 <int>, date_week3 <int>, date_week4 <int>, date_mday7 <int>,\n#   date_month.lbl_01 <dbl>, date_month.lbl_02 <dbl>, date_month.lbl_03 <dbl>,\n#   date_month.lbl_04 <dbl>, date_month.lbl_05 <dbl>, …\n\n\nonce the recipe is ready, we can set up the machine learning pipelines.\nElastic Net\n\nwe will first build the model\nnext, we will make that model into a fitted workflow\n\n\nmodelSpec_glmnet <- linear_reg(penalty = 0.01, mixture = 0.05) %>%\n  set_engine(\"glmnet\")\n\nworkflowFit_glmnet <- workflow() %>%\n  add_model(modelSpec_glmnet) %>%\n  add_recipe(recipeSpecs %>%\n               step_rm(date)) %>%\n  fit(training(splits))\n\nRandom Forest - similar process as the Elastic Net\n\nmodelSpec_rf <- rand_forest(trees = 500, min_n = 50, mode = \"regression\") %>%\n  set_engine(\"randomForest\")\n\nworkflowFit_rf <- workflow() %>%\n  add_model(modelSpec_rf) %>%\n  add_recipe(recipeSpecs %>%\n               step_rm(date)) %>%\n  fit(training(splits))\n\nAdding new models - XGBoost - SVM\nXGBoost:\n\nrecipeSpecsParsnip <- recipeSpecs %>%\n  update_role(date, new_role = \"ID\")\n\nworkflowFit_xgboost <- workflow() %>%\n  add_model(\n    boost_tree(\n      trees = 500,\n      min_n = 1,\n      tree_depth = 15,\n      mode = \"regression\"\n    ) %>%\n      set_engine(\"xgboost\")\n  ) %>%\n  add_recipe(recipeSpecsParsnip) %>%\n  fit(training(splits))\n\nSVM:\n\nworkflowFit_svm <- workflow() %>%\n  add_model(\n    svm_rbf(\n      cost = 1,\n      margin = 0.1\n    ) %>%\n      set_engine(\"kernlab\") %>%\n      set_mode(\"regression\")\n  ) %>%\n  add_recipe(recipeSpecsParsnip) %>%\n  fit(training(splits))\n\nNew Hybrid Models\n\nthese combine automated algorithms with machine learning\n\nProphet Boost\n\nalgorithm works by modelling the univariate series using Prophet\nuses regresses supplied via the preprocessing rrrcipe\nregresses the prophet residuals with the XGBoost model\n\n\nmodelSpec_prophetBoost <- prophet_boost() %>%\n  set_engine(\"prophet_xgboost\", yearly.seasonality = TRUE)\n\nworkflowFit_prophetBoost <- workflow() %>%\n  add_model(modelSpec_prophetBoost) %>%\n  add_recipe(recipeSpecs) %>%\n  fit(training(splits))\n\nARIMA Boosted:\n\nworkflowFit_arimaBoost <- workflow() %>%\n  add_model(\n    arima_boost(\n      non_seasonal_ar = 2,\n      non_seasonal_differences = 1,\n      non_seasonal_ma = 2,\n      trees = 500,\n      min_n = 1,\n      tree_depth = 15\n    ) %>%\n      set_engine(\"auto_arima_xgboost\")\n  ) %>%\n  add_recipe(recipeSpecs) %>%\n  fit(training(splits))\n\nModeltime Table\n\norganizes the models with IDs and creates generic descriptions too help us keep track of our models\n\n\nmodelTable <- modeltime_table(\n  modelFitArima,\n  modelFitProphet,\n  workflowFit_glmnet,\n  workflowFit_rf,\n  workflowFit_svm,\n  workflowFit_xgboost,\n  workflowFit_arimaBoost,\n  workflowFit_prophetBoost\n) %>%\n  update_model_description(1, \"ARIMA\") %>%\n  update_model_description(2, \"Prophet\") %>%\n  update_model_description(3, \"glmNet\") %>%\n  update_model_description(4, \"Random Forest\") %>%\n  update_model_description(5, \"SVM\") %>%\n  update_model_description(6, \"XGBoost\") %>%\n  update_model_description(7, \"ARIMA Boost\") %>%\n  update_model_description(8, \"Prophet Boost\")\n\nmodelTable\n\n# Modeltime Table\n# A tibble: 8 × 3\n  .model_id .model     .model_desc  \n      <int> <list>     <chr>        \n1         1 <fit[+]>   ARIMA        \n2         2 <fit[+]>   Prophet      \n3         3 <workflow> glmNet       \n4         4 <workflow> Random Forest\n5         5 <workflow> SVM          \n6         6 <workflow> XGBoost      \n7         7 <workflow> ARIMA Boost  \n8         8 <workflow> Prophet Boost\n\n\nCalibration\n\nmodel calibration is used to quantify error and estimate confidence intervals\ntwo columns will be generated: .type and .calibration_data\n.calibration_data includes the actual values, fitted values and the residuals for the testing set\n\n\ncalibrationTable <- modelTable %>%\n  modeltime_calibrate(testing(splits))\n\ncalibrationTable\n\n# Modeltime Table\n# A tibble: 8 × 5\n  .model_id .model     .model_desc   .type .calibration_data\n      <int> <list>     <chr>         <chr> <list>           \n1         1 <fit[+]>   ARIMA         Test  <tibble [36 × 4]>\n2         2 <fit[+]>   Prophet       Test  <tibble [36 × 4]>\n3         3 <workflow> glmNet        Test  <tibble [36 × 4]>\n4         4 <workflow> Random Forest Test  <tibble [36 × 4]>\n5         5 <workflow> SVM           Test  <tibble [36 × 4]>\n6         6 <workflow> XGBoost       Test  <tibble [36 × 4]>\n7         7 <workflow> ARIMA Boost   Test  <tibble [36 × 4]>\n8         8 <workflow> Prophet Boost Test  <tibble [36 × 4]>\n\n\nForecast (Testing Set)\n\nwith the calibrated data, we can visualize testing predictions (forecast)\n\n\nforecastTable <- calibrationTable %>%\n  modeltime_forecast(actual_data = vaByMarketTable)\n\nforecastTable\n\n# A tibble: 828 × 7\n   .model_id .model_desc .key   .index     .value .conf_lo .conf_hi\n       <int> <chr>       <fct>  <date>      <dbl>    <dbl>    <dbl>\n 1        NA ACTUAL      actual 1978-01-01   99.0       NA       NA\n 2        NA ACTUAL      actual 1978-02-01   87.0       NA       NA\n 3        NA ACTUAL      actual 1978-03-01   95.5       NA       NA\n 4        NA ACTUAL      actual 1978-04-01   84.2       NA       NA\n 5        NA ACTUAL      actual 1978-05-01   89.7       NA       NA\n 6        NA ACTUAL      actual 1978-06-01   78.5       NA       NA\n 7        NA ACTUAL      actual 1978-07-01   96.4       NA       NA\n 8        NA ACTUAL      actual 1978-08-01  113.        NA       NA\n 9        NA ACTUAL      actual 1978-09-01   87.8       NA       NA\n10        NA ACTUAL      actual 1978-10-01   99.6       NA       NA\n# … with 818 more rows\n\n\nPlotting the forecasts:\n\nforecastPlots <- forecastTable %>%\n  filter(.model_desc != \"ACTUAL\") %>%\n  plot_modeltime_forecast(\n    .interactive = FALSE,\n    .facet_vars = .model_desc,\n    .facet_ncol = 4,\n    .facet_scales = \"fixed\",\n    .legend_show = FALSE\n  ) +\n  geom_line(\n    data = forecastTable %>%\n      filter(.model_desc == \"ACTUAL\") %>%\n      select(.index, .value),\n    size = 0.3\n  ) +\n  labs(\n    title = \"\", y = \"No. of Visitors\", x = \"Year\"\n  ) +\n  theme_bw() +\n  theme(legend.position = \"none\")\n\nggplotly(forecastPlots)\n\n\n\n\n\nAnother way to plot it: - scraping this!\n\n# forecastTable %>%\n#   filter(.model_desc != \"ACTUAL\") %>%\n#   group_by(.model_desc) %>%\n#   plot_time_series(.index, \n#                    .value, \n#                    .facet_ncol = 2, \n#                    .facet_scales = \"free\", \n#                    .interactive = TRUE)\n\nAccuracy (Testing Set)\n\nto calculate the testing accuracy to compare the models\nneed to explore to find out how to interpret this table!\nscraping this!\n\n\n# calibrationTable %>%\n#   modeltime_accuracy() %>%\n#   table_modeltime_accuracy(.interactive = FALSE)\n\nAnother way to plot accuracy:\n\naccuracyTable <- calibrationTable %>%\n  modeltime_accuracy() %>%\n  select(.model_desc, mae, mape, mase, smape, rmse, rsq) %>%\n  reactable(\n    columns = list(\n      .model_desc = colDef(name = \"Model\"),\n      mae = colDef(name = \"Mean Absolute Error\", format = colFormat(digits = 2)),\n      mape = colDef(name = \"Mean Absolute Percentage Error\", format = colFormat(digits = 2)),\n      mase = colDef(name = \"Mean Absolute Scaled Error\", format = colFormat(digits = 2)),\n      smape = colDef(name = \"Symmetric Mean Absolute Percentage Error\", format = colFormat(digits = 2)),\n      rmse = colDef(name = \"Root Mean Squared Error\", format = colFormat(digits = 2)),\n      rsq = colDef(name = \"R-Squared\", format = colFormat(digits = 2))\n    ),\n    highlight = TRUE,\n    striped = TRUE,\n    searchable = TRUE,\n    showPageSizeOptions = FALSE\n  )\n\naccuracyTable\n\n\n\n\n\n\nNow that we have done forecasting, let’s do some refitting:\n\nrefitTable <- calibrationTable %>%\n  modeltime_refit(vaByMarketTable) %>%\n  modeltime_forecast(h = \"3 years\",\n                     actual_data = vaByMarketTable) %>%\n  mutate(.model_desc = str_replace_all(.model_desc, \"UPDATE: ARIMA\\\\(1,1,0\\\\)\\\\(2,0,0\\\\)\\\\[12\\\\]\", \"ARIMA\")) %>%\n  mutate(.model_desc = str_replace_all(.model_desc, \"W/ XGBOOST ERRORS\", \"Boost\"))\n\nrefitTable\n\n# A tibble: 828 × 7\n   .model_id .model_desc .key   .index     .value .conf_lo .conf_hi\n       <int> <chr>       <fct>  <date>      <dbl>    <dbl>    <dbl>\n 1        NA ACTUAL      actual 1978-01-01   99.0       NA       NA\n 2        NA ACTUAL      actual 1978-02-01   87.0       NA       NA\n 3        NA ACTUAL      actual 1978-03-01   95.5       NA       NA\n 4        NA ACTUAL      actual 1978-04-01   84.2       NA       NA\n 5        NA ACTUAL      actual 1978-05-01   89.7       NA       NA\n 6        NA ACTUAL      actual 1978-06-01   78.5       NA       NA\n 7        NA ACTUAL      actual 1978-07-01   96.4       NA       NA\n 8        NA ACTUAL      actual 1978-08-01  113.        NA       NA\n 9        NA ACTUAL      actual 1978-09-01   87.8       NA       NA\n10        NA ACTUAL      actual 1978-10-01   99.6       NA       NA\n# … with 818 more rows\n\n\nNow we will use the refitted data and do forward forecasting:\n\nrefitPlots <- refitTable %>%\n  filter(.model_desc != \"ACTUAL\") %>%\n  plot_modeltime_forecast(\n    .interactive = FALSE,\n    .facet_vars = .model_desc,\n    .facet_ncol = 4,\n    .facet_scales = \"fixed\",\n    .legend_show = FALSE\n  ) +\n  geom_line(\n    data = forecastTable %>%\n      filter(.model_desc == \"ACTUAL\") %>%\n      select(.index, .value),\n    size = 0.3\n  ) +\n  labs(\n    title = \"\"\n  ) +\n  theme_bw() +\n  theme(legend.position = \"none\")\n\nggplotly(refitPlots)\n\n\n\n\n\nNow we have our forecasts and refit + forecasts. Let’s plot the residuals now:\n\nresidualsTable <- calibrationTable %>%\n  modeltime_residuals()\n\nresidualsPlots <- residualsTable %>%\n  plot_modeltime_residuals(\n    .interactive = FALSE,\n    .type = \"timeplot\",\n    .facet_vars = .model_desc,\n    .facet_ncol = 4,\n    .facet_scales = \"fixed\"\n  ) +\n  labs(\n    title = \"\",\n    y = \"Residuals\"\n  ) +\n  theme_bw() +\n  theme(legend.position = \"none\")\n\nggplotly(residualsPlots)\n\n\n\n\n\nxxx"
  }
]