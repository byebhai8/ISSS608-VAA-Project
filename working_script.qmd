---
title: "Working Script"
author: "Bhairavi"
execute:
  warning: false
---

# 1. Load necessary libraries

```{r}
pacman::p_load(readxl, tidyverse)
```

# 2. Load the dataset

```{r}
vaByMarketRaw <- read_excel("outputFile -International Visitor Arrivals.xlsx", sheet = "T1", skip = 10)
vaByDemoRaw <- read_excel("outputFile -International Visitor Arrivals.xlsx", sheet = "T2", skip = 10)
vaByStayRaw <- read_excel("outputFile -International Visitor Arrivals.xlsx", sheet = "T3", skip = 9)
```

# 3. Cleansing the dataset

### 3.1 Tourism Markets file

This file

- contains the international visitor arrivals by inbound tourism markets (monthly)
- excludes arrivals of Malaysians by land
- feb 1991 has a sharp decline due to Gulf crisis
- data for Germany prior to 1991 refers to West Germany only
- all numbers are counts

The following was done to cleanup the vaByMarketRaw dataframe:

- remove the bottom few rows as they were unnecessary for our visualizations
- create a new column to assign the value of Region to the respective Countries
- rename fields and rearrange the columns
- filter out rows that are not needed anymore
- pivot date (month-year) and the number of visitors to reduce the number of columns

```{r}
vaByMarket <- slice(vaByMarketRaw, 2:(62))

colnames(vaByMarket)[1] <- "Data"

vaByMarket$Region <-
  ifelse(vaByMarket$Data %in% c("Brunei Darussalam", "Indonesia", "Malaysia", "Myanmar", "Philippines", "Thailand", "Vietnam", "Other Markets In Southeast Asia"), "Southeast Asia",
  ifelse(vaByMarket$Data %in% c("China", "Hong Kong SAR", "Taiwan", "Other Markets In Greater China"), "Greater China",
  ifelse(vaByMarket$Data %in% c("Japan", "South Korea", "Other Markets In North Asia"), "North Asia",
  ifelse(vaByMarket$Data %in% c("Bangladesh", "India", "Pakistan", "Sri Lanka", "Other Markets In South Asia"), "South Asia",
  ifelse(vaByMarket$Data %in% c("Iran", "Israel", "Kuwait", "Saudi Arabia", "United Arab Emirates", "Other Markets In West Asia"), "West Asia",
  ifelse(vaByMarket$Data %in% c("Canada", "USA", "Other Markets In Americas"), "Americas",
  ifelse(vaByMarket$Data %in% c("Belgium & Luxembourg", "Denmark", "Finland", "France", "Germany", "Italy", "Netherlands", "Norway", "Rep Of Ireland", "Russian Federation", "Spain", "Sweden", "Switzerland", "United Kingdom", "Other Markets In Europe"), "Europe",
  ifelse(vaByMarket$Data %in% c("Australia", "New Zealand", "Other Markets In Oceania"), "Oceania",
  ifelse(vaByMarket$Data %in% c("Egypt", "Mauritius", "South Africa (Rep Of)", "Other Markets In Africa"), "Africa",
  ifelse(vaByMarket$Data %in% c("Others"), "Others", "NA"
  ))))))))))

vaByMarket <- vaByMarket %>%
  select(542, 1, 2:541)

colnames(vaByMarket)[2] <- "Country"

# sapply(vaByMarket, class)

vaByMarket <- vaByMarket %>%
  mutate_at(vars(-one_of("Region", "Country")), as.numeric) %>%
  filter(vaByMarket$Region != "NA") %>%
  pivot_longer(cols = ! c("Region", "Country"), names_to = "Period", values_to = "Visitors") %>%
  mutate(Period = as.Date(paste(Period, "01"), "%Y %B %d")) %>%
  mutate(Year = year(Period))
```

# 4. Preparations for visualizations

to find the total number of visitors (regardless of date range):

```{r}
totalVisitors <- sum(vaByMarket$Visitors, na.rm = TRUE)
totalVisitors
```

to find the min and max year:

```{r}
minYear <- min(year(vaByMarket$Period))
minYear

maxYear <- max(year(vaByMarket$Period))
maxYear
```

to find the country where most visitors are from:

```{r}
visitorsByCountry <- vaByMarket %>%
  group_by(Country) %>%
  summarize(Visitors = sum(Visitors, na.rm = TRUE))
  
visitorsByCountry <- visitorsByCountry[order(visitorsByCountry$Visitors, decreasing = TRUE), ]
visitorsByCountry

mostFrom <- head(visitorsByCountry$Country, 1)
mostFrom
```

to find the number of countries that visited us:

```{r}
temp <- vaByMarket[vaByMarket$Year >= 1984 & vaByMarket$Year <= 1990, ]

numCountries <- nrow(temp %>%
    filter(!is.na(Visitors)) %>%
    count(Country))
numCountries
```

to list of regions

```{r}
listRegions <- unique(vaByMarket$Region)
listRegions
```

xx

# 5. Visualizations

plotting visitors across time chart:

install the timetk package (recommended by Prof Kam)

```{r}
pacman::p_load(timetk, lubridate, ggplot2, plotly, ggHoriPlot)
```

Time Series Plot for Overall Trend (timetk)

```{r}
timeSeriesOverall <- vaByMarket %>%
  group_by(Period) %>%
  summarise(Visitors = sum(Visitors, na.rm = TRUE))

timeSeriesOverall %>%
  plot_time_series(Period, Visitors, .interactive = TRUE)
```

Cycle Plot for Overall Trend
TBC, Cycle Plot is not working!!

```{r}

# vaByMarket[is.na(vaByMarket)] = 0
# 
# monthAvg <- vaByMarket %>%
#   mutate(Month = month(Period)) %>%
#   group_by(Month) %>%
#   summarise(avgValue = mean(Visitors))
# 
# cyclePlot <- vaByMarket %>%
#   group_by(Period) %>%
#   summarise(Visitors = sum(Visitors, na.rm = TRUE)) %>%
#   mutate(Month = as.character(Period, format = '%b')) %>%
#   mutate(Visitors = round(Visitors/1000, digits = 0))
# 
# figCyclePlot <- ggplot() +
#   geom_line(data = cyclePlot,
#             aes(x = as.character(Period, format = '%y'),
#                 y = Visitors,
#                 group = Month)) +
#   geom_hline(aes(yintercept = avgValue),
#              data = monthAvg,
#              colour = "red",
#              size = 0.3) +
#   labs(x = "Date", y = "No. of Visitors", title = "Overall Trend of Visitor Arrivals by month and year, 1978 to 2022") +
#   facet_grid(~ factor(Month, levels = c("Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"))) +
#   theme_bw()
# 
# ggplotly(figCyclePlot)

```

Compare two regions using the Horizon Plot for Regional Trend?

```{r}
vaByMarket %>%
  group_by(Period, Region) %>%
  summarise(Visitors = sum(Visitors)) %>%
  filter(Region == "South Asia")  %>%
  ggplot() +
  geom_horizon(aes(x = Period, y =  Visitors), origin = "midpoint", horizonscale = 6) +
  facet_grid(Region~.) +
  scale_fill_hcl(palette = "RdBu") +
  scale_x_date(expand = c(0,0), date_breaks = "3 year", date_labels = " %b %y") +
  theme_minimal() +
  theme(panel.spacing.y = unit(0, "lines"), 
        strip.text.y = element_text(size = 10, angle = 0, hjust = 0),
        legend.position = 'none',
        axis.text.y = element_blank(),
        axis.text.x = element_text(size = 7),
        axis.title.y = element_blank(),
        axis.title.x = element_blank(),
        axis.ticks.y = element_blank(),
        panel.border = element_blank())
```


Time Series Plot for Regional Trend (ggplotly)

```{r}
timeseriesRegion <- vaByMarket %>%
  group_by(Region, Period) %>%
  summarise(Visitors = sum(Visitors, na.rm = TRUE)) %>%
  mutate(Visitors = round(Visitors/1000, digits = 0))

figTimeseriesRegion <- ggplot(data = timeseriesRegion, aes(x = Period, y = Visitors)) +
  geom_line(aes(colour = Region)) +
  labs(x = "Date", y = "No. of Visitors (K)", title = "Overall Trend of Visitor Arrivals by Region, 1978 to 2022") +
  theme_bw()

ggplotly(figTimeseriesRegion)
```

Time Series Plot for Country Trend (ggplotly)

```{r}
timeseriesCountry <- vaByMarket %>%
  group_by(Country, Period) %>%
  summarise(Visitors = sum(Visitors, na.rm = TRUE)) %>%
  mutate(Visitors = round(Visitors/1000, digits = 0))

figTimeseriesCountry <- ggplot(data = timeseriesCountry, aes(x = Period, y = Visitors)) +
  geom_line(aes(colour = Country)) +
  labs(x = "Date", y = "No. of Visitors (K)", title = "Overall Trend of Visitor Arrivals, 1978 to 2022") +
  theme_bw()

ggplotly(figTimeseriesCountry)
```

# 5. Forecasting

reference: https://www.r-bloggers.com/2020/06/introducing-modeltime-tidy-time-series-forecasting-using-tidymodels/ 

loading libraries

```{r}
pacman::p_load(modeltime, kernlab, reactable, tidymodels)
```

only keep the date and value columns for forecasting

```{r}
vaByMarketTable <- vaByMarket %>%
  group_by(Period) %>%
  summarise(visitors = round(sum(Visitors, na.rm = TRUE))/1000) %>% # converted to thousands
  set_names(c("date", "value"))
vaByMarketTable
```

let's create a train/test set"

```{r}
splits <- vaByMarketTable %>%
  time_series_split(
    assess = "3 years",
    cumulative = TRUE
  )
splits
```

let's plot the train/test split to visualize the split:

```{r}
splits %>%
  tk_time_series_cv_plan() %>%
  plot_time_series_cv_plan(date, value, .interactive = FALSE)
```

we will modelling using modeltime and parsnip libraries

Basic Auto ARIMA fitting

```{r}
modelFitArima <- arima_reg(
  non_seasonal_ar = 2,
  non_seasonal_differences = 1,
  non_seasonal_ma = 2
) %>%
  set_engine("auto_arima") %>%
  fit(value ~ date, training(splits))
modelFitArima
```

Prophet

```{r}
modelFitProphet <- prophet_reg() %>%
  set_engine("prophet", yearly.seasonality = TRUE) %>%
  fit(value ~ date, training(splits))
modelFitProphet
```

Machine Learning Models
- create a pre-processing recipe
- create model specs
- use workflow to combine model specs, pre-processing and fit model

Pre-processing Recipe:

```{r}
recipeSpecs <- recipe(value ~ date, training(splits)) %>%
  step_timeseries_signature(date) %>%
  step_dummy(all_nominal())

recipeSpecs %>%
  prep() %>%
  juice()
```

once the recipe is ready, we can set up the machine learning pipelines.

Elastic Net

- we will first build the model
- next, we will make that model into a fitted workflow

```{r}
modelSpec_glmnet <- linear_reg(penalty = 0.01, mixture = 0.05) %>%
  set_engine("glmnet")

workflowFit_glmnet <- workflow() %>%
  add_model(modelSpec_glmnet) %>%
  add_recipe(recipeSpecs %>%
               step_rm(date)) %>%
  fit(training(splits))
```

Random Forest
- similar process as the Elastic Net

```{r}
modelSpec_rf <- rand_forest(trees = 500, min_n = 50, mode = "regression") %>%
  set_engine("randomForest")

workflowFit_rf <- workflow() %>%
  add_model(modelSpec_rf) %>%
  add_recipe(recipeSpecs %>%
               step_rm(date)) %>%
  fit(training(splits))
```

Adding new models
- XGBoost
- SVM

XGBoost:

```{r}
recipeSpecsParsnip <- recipeSpecs %>%
  update_role(date, new_role = "ID")

workflowFit_xgboost <- workflow() %>%
  add_model(
    boost_tree(
      trees = 500,
      min_n = 1,
      tree_depth = 15,
      mode = "regression"
    ) %>%
      set_engine("xgboost")
  ) %>%
  add_recipe(recipeSpecsParsnip) %>%
  fit(training(splits))
```

SVM:

```{r}
workflowFit_svm <- workflow() %>%
  add_model(
    svm_rbf(
      cost = 1,
      margin = 0.1
    ) %>%
      set_engine("kernlab") %>%
      set_mode("regression")
  ) %>%
  add_recipe(recipeSpecsParsnip) %>%
  fit(training(splits))
```

New Hybrid Models

- these combine automated algorithms with machine learning

Prophet Boost

- algorithm works by modelling the univariate series using Prophet
- uses regresses supplied via the preprocessing rrrcipe
- regresses the prophet residuals with the XGBoost model

```{r}
modelSpec_prophetBoost <- prophet_boost() %>%
  set_engine("prophet_xgboost", yearly.seasonality = TRUE)

workflowFit_prophetBoost <- workflow() %>%
  add_model(modelSpec_prophetBoost) %>%
  add_recipe(recipeSpecs) %>%
  fit(training(splits))
```

ARIMA Boosted:

```{r}
workflowFit_arimaBoost <- workflow() %>%
  add_model(
    arima_boost(
      non_seasonal_ar = 2,
      non_seasonal_differences = 1,
      non_seasonal_ma = 2,
      trees = 500,
      min_n = 1,
      tree_depth = 15
    ) %>%
      set_engine("auto_arima_xgboost")
  ) %>%
  add_recipe(recipeSpecs) %>%
  fit(training(splits))
```

Modeltime Table

- organizes the models with IDs and creates generic descriptions too help us keep track of our models

```{r}
modelTable <- modeltime_table(
  modelFitArima,
  modelFitProphet,
  workflowFit_glmnet,
  workflowFit_rf,
  workflowFit_svm,
  workflowFit_xgboost,
  workflowFit_arimaBoost,
  workflowFit_prophetBoost
) %>%
  update_model_description(1, "ARIMA") %>%
  update_model_description(2, "Prophet") %>%
  update_model_description(3, "glmNet") %>%
  update_model_description(4, "Random Forest") %>%
  update_model_description(5, "SVM") %>%
  update_model_description(6, "XGBoost") %>%
  update_model_description(7, "ARIMA Boost") %>%
  update_model_description(8, "Prophet Boost")

modelTable
```

Calibration

- model calibration is used to quantify error and estimate confidence intervals
- two columns will be generated: .type and .calibration_data
- .calibration_data includes the actual values, fitted values and the residuals for the testing set

```{r}
calibrationTable <- modelTable %>%
  modeltime_calibrate(testing(splits))

calibrationTable
```

Forecast (Testing Set)

- with the calibrated data, we can visualize testing predictions (forecast)

```{r}
forecastTable <- calibrationTable %>%
  modeltime_forecast(actual_data = vaByMarketTable)

forecastTable
```

Plotting the forecasts:

```{r}
forecastPlots <- forecastTable %>%
  filter(.model_desc != "ACTUAL") %>%
  plot_modeltime_forecast(
    .interactive = FALSE,
    .facet_vars = .model_desc,
    .facet_ncol = 4,
    .facet_scales = "fixed",
    .legend_show = FALSE
  ) +
  geom_line(
    data = forecastTable %>%
      filter(.model_desc == "ACTUAL") %>%
      select(.index, .value),
    size = 0.3
  ) +
  labs(
    title = "", y = "No. of Visitors", x = "Year"
  ) +
  theme_bw() +
  theme(legend.position = "none")

ggplotly(forecastPlots)

```

Another way to plot it:
- scraping this!

```{r}
# forecastTable %>%
#   filter(.model_desc != "ACTUAL") %>%
#   group_by(.model_desc) %>%
#   plot_time_series(.index, 
#                    .value, 
#                    .facet_ncol = 2, 
#                    .facet_scales = "free", 
#                    .interactive = TRUE)
```

Accuracy (Testing Set)

- to calculate the testing accuracy to compare the models
- need to explore to find out how to interpret this table!
- scraping this!

```{r}
# calibrationTable %>%
#   modeltime_accuracy() %>%
#   table_modeltime_accuracy(.interactive = FALSE)
```

Another way to plot accuracy:

```{r}
accuracyTable <- calibrationTable %>%
  modeltime_accuracy() %>%
  select(.model_desc, mae, mape, mase, smape, rmse, rsq) %>%
  reactable(
    columns = list(
      .model_desc = colDef(name = "Model"),
      mae = colDef(name = "Mean Absolute Error", format = colFormat(digits = 2)),
      mape = colDef(name = "Mean Absolute Percentage Error", format = colFormat(digits = 2)),
      mase = colDef(name = "Mean Absolute Scaled Error", format = colFormat(digits = 2)),
      smape = colDef(name = "Symmetric Mean Absolute Percentage Error", format = colFormat(digits = 2)),
      rmse = colDef(name = "Root Mean Squared Error", format = colFormat(digits = 2)),
      rsq = colDef(name = "R-Squared", format = colFormat(digits = 2))
    ),
    highlight = TRUE,
    striped = TRUE,
    searchable = TRUE,
    showPageSizeOptions = FALSE
  )

accuracyTable
```

Now that we have done forecasting, let's do some refitting:

```{r}
refitTable <- calibrationTable %>%
  modeltime_refit(vaByMarketTable) %>%
  modeltime_forecast(h = "3 years",
                     actual_data = vaByMarketTable) %>%
  mutate(.model_desc = str_replace_all(.model_desc, "UPDATE: ARIMA\\(1,1,0\\)\\(2,0,0\\)\\[12\\]", "ARIMA")) %>%
  mutate(.model_desc = str_replace_all(.model_desc, "W/ XGBOOST ERRORS", "Boost"))

refitTable
```

Now we will use the refitted data and do forward forecasting:

```{r}
refitPlots <- refitTable %>%
  filter(.model_desc != "ACTUAL") %>%
  plot_modeltime_forecast(
    .interactive = FALSE,
    .facet_vars = .model_desc,
    .facet_ncol = 4,
    .facet_scales = "fixed",
    .legend_show = FALSE
  ) +
  geom_line(
    data = forecastTable %>%
      filter(.model_desc == "ACTUAL") %>%
      select(.index, .value),
    size = 0.3
  ) +
  labs(
    title = ""
  ) +
  theme_bw() +
  theme(legend.position = "none")

ggplotly(refitPlots)
```

Now we have our forecasts and refit + forecasts. Let's plot the residuals now:

```{r}
residualsTable <- calibrationTable %>%
  modeltime_residuals()

residualsPlots <- residualsTable %>%
  plot_modeltime_residuals(
    .interactive = FALSE,
    .type = "timeplot",
    .facet_vars = .model_desc,
    .facet_ncol = 4,
    .facet_scales = "fixed"
  ) +
  labs(
    title = "",
    y = "Residuals"
  ) +
  theme_bw() +
  theme(legend.position = "none")

ggplotly(residualsPlots)
```

xxx

